{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "# !pip install pandas\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data from the csv file located inside datasets folder\n",
    "df = pd.read_csv('datasets/data.csv', encoding = \"ISO-8859-1\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stn_code</th>\n",
       "      <th>sampling_date</th>\n",
       "      <th>state</th>\n",
       "      <th>location</th>\n",
       "      <th>agency</th>\n",
       "      <th>type</th>\n",
       "      <th>so2</th>\n",
       "      <th>no2</th>\n",
       "      <th>rspm</th>\n",
       "      <th>spm</th>\n",
       "      <th>location_monitoring_station</th>\n",
       "      <th>pm2_5</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150</td>\n",
       "      <td>February - M021990</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Residential, Rural and other Areas</td>\n",
       "      <td>4.80</td>\n",
       "      <td>17.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1990-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>151</td>\n",
       "      <td>February - M021990</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Industrial Area</td>\n",
       "      <td>3.10</td>\n",
       "      <td>7.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1990-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>152</td>\n",
       "      <td>February - M021990</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Residential, Rural and other Areas</td>\n",
       "      <td>6.20</td>\n",
       "      <td>28.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1990-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150</td>\n",
       "      <td>March - M031990</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Residential, Rural and other Areas</td>\n",
       "      <td>6.30</td>\n",
       "      <td>14.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1990-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151</td>\n",
       "      <td>March - M031990</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Industrial Area</td>\n",
       "      <td>4.70</td>\n",
       "      <td>7.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1990-03-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stn_code       sampling_date           state   location agency  \\\n",
       "0      150  February - M021990  Andhra Pradesh  Hyderabad    NaN   \n",
       "1      151  February - M021990  Andhra Pradesh  Hyderabad    NaN   \n",
       "2      152  February - M021990  Andhra Pradesh  Hyderabad    NaN   \n",
       "3      150     March - M031990  Andhra Pradesh  Hyderabad    NaN   \n",
       "4      151     March - M031990  Andhra Pradesh  Hyderabad    NaN   \n",
       "\n",
       "                                 type  so2   no2  rspm  spm  \\\n",
       "0  Residential, Rural and other Areas 4.80 17.40   NaN  NaN   \n",
       "1                     Industrial Area 3.10  7.00   NaN  NaN   \n",
       "2  Residential, Rural and other Areas 6.20 28.50   NaN  NaN   \n",
       "3  Residential, Rural and other Areas 6.30 14.70   NaN  NaN   \n",
       "4                     Industrial Area 4.70  7.50   NaN  NaN   \n",
       "\n",
       "  location_monitoring_station  pm2_5        date  \n",
       "0                         NaN    NaN  1990-02-01  \n",
       "1                         NaN    NaN  1990-02-01  \n",
       "2                         NaN    NaN  1990-02-01  \n",
       "3                         NaN    NaN  1990-03-01  \n",
       "4                         NaN    NaN  1990-03-01  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 435742 rows and 13 columns in the dataframe\n"
     ]
    }
   ],
   "source": [
    "# check the shape of the dataframe\n",
    "print(f\"There are {df.shape[0]} rows and {df.shape[1]} columns in the dataframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 435742 entries, 0 to 435741\n",
      "Data columns (total 13 columns):\n",
      " #   Column                       Non-Null Count   Dtype  \n",
      "---  ------                       --------------   -----  \n",
      " 0   stn_code                     291665 non-null  object \n",
      " 1   sampling_date                435739 non-null  object \n",
      " 2   state                        435742 non-null  object \n",
      " 3   location                     435739 non-null  object \n",
      " 4   agency                       286261 non-null  object \n",
      " 5   type                         430349 non-null  object \n",
      " 6   so2                          401096 non-null  float64\n",
      " 7   no2                          419509 non-null  float64\n",
      " 8   rspm                         395520 non-null  float64\n",
      " 9   spm                          198355 non-null  float64\n",
      " 10  location_monitoring_station  408251 non-null  object \n",
      " 11  pm2_5                        9314 non-null    float64\n",
      " 12  date                         435735 non-null  object \n",
      "dtypes: float64(5), object(8)\n",
      "memory usage: 43.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# check the basic info of the dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stn_code                        object\n",
       "sampling_date                   object\n",
       "state                           object\n",
       "location                        object\n",
       "agency                          object\n",
       "type                            object\n",
       "so2                            float64\n",
       "no2                            float64\n",
       "rspm                           float64\n",
       "spm                            float64\n",
       "location_monitoring_station     object\n",
       "pm2_5                          float64\n",
       "date                            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the type of data for each column\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pm2_5                          426428\n",
       "spm                            237387\n",
       "agency                         149481\n",
       "stn_code                       144077\n",
       "rspm                            40222\n",
       "so2                             34646\n",
       "location_monitoring_station     27491\n",
       "no2                             16233\n",
       "type                             5393\n",
       "date                                7\n",
       "sampling_date                       3\n",
       "location                            3\n",
       "state                               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for null values in descending order\n",
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agency                         149481\n",
       "stn_code                       144077\n",
       "location_monitoring_station     27491\n",
       "type                             5393\n",
       "date                                7\n",
       "sampling_date                       3\n",
       "location                            3\n",
       "state                               0\n",
       "so2                                 0\n",
       "no2                                 0\n",
       "rspm                                0\n",
       "spm                                 0\n",
       "pm2_5                               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for the float64 columns, fill the null values with the mean of the column\n",
    "# make a list of the float64 columns\n",
    "float64_cols = df.select_dtypes(include=['float64']).columns.tolist()\n",
    "# find the mean and median of each column\n",
    "mean = df[float64_cols].mean()\n",
    "#print(mean)\n",
    "median = df[float64_cols].median()\n",
    "#print(median)\n",
    "\n",
    "# fill the null values with the median of the column\n",
    "df[float64_cols] = df[float64_cols].fillna(median)\n",
    "\n",
    "# check for null values in descending order\n",
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stn_code                        745\n",
       "sampling_date                  5485\n",
       "state                            37\n",
       "location                        304\n",
       "agency                           64\n",
       "type                             10\n",
       "so2                            4197\n",
       "no2                            6864\n",
       "rspm                           6065\n",
       "spm                            6668\n",
       "location_monitoring_station     991\n",
       "pm2_5                           433\n",
       "date                           5067\n",
       "dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for unique values in the dataframe\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "674\n",
      "There are 435068 rows and 13 columns in the dataframe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "stn_code                        745\n",
       "sampling_date                  5485\n",
       "state                            37\n",
       "location                        304\n",
       "agency                           64\n",
       "type                             10\n",
       "so2                            4197\n",
       "no2                            6864\n",
       "rspm                           6065\n",
       "spm                            6668\n",
       "location_monitoring_station     991\n",
       "pm2_5                           433\n",
       "date                           5067\n",
       "dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for duplicate rows in the dataframe\n",
    "print(df.duplicated().sum())\n",
    "\n",
    "# drop the duplicate rows\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# check rows and columns after dropping the duplicates\n",
    "print(f\"There are {df.shape[0]} rows and {df.shape[1]} columns in the dataframe\")\n",
    "\n",
    "# are the unique values in the datraframe got affected?\n",
    "df.nunique()\n",
    "\n",
    "# they are same as before, so we can proceed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the columns which are not required\n",
    "# create a list of columns to be dropped\n",
    "cols_to_drop = ['agency', 'stn_code', 'date', 'sampling_date', 'location_monitoring_station']\n",
    "\n",
    "# drop the columns\n",
    "df.drop(columns=cols_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 435068 entries, 0 to 435741\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count   Dtype  \n",
      "---  ------    --------------   -----  \n",
      " 0   state     435068 non-null  object \n",
      " 1   location  435065 non-null  object \n",
      " 2   type      429711 non-null  object \n",
      " 3   so2       435068 non-null  float64\n",
      " 4   no2       435068 non-null  float64\n",
      " 5   rspm      435068 non-null  float64\n",
      " 6   spm       435068 non-null  float64\n",
      " 7   pm2_5     435068 non-null  float64\n",
      "dtypes: float64(5), object(3)\n",
      "memory usage: 29.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the so2 individual index (si)\n",
    "def cal_si(so2):\n",
    "    si = 0\n",
    "    if (so2 <= 40):\n",
    "        si = so2 * 50 / 40\n",
    "    elif (so2 <= 80):\n",
    "        si = 50 + (so2 - 40) * 50 / 40\n",
    "    elif (so2 <= 380):\n",
    "        si = 100 + (so2 - 80) * 100 / 300\n",
    "    elif (so2 <= 800):\n",
    "        si = 200 + (so2 - 380) * 100 / 420\n",
    "    elif (so2 <= 1600):\n",
    "        si = 300 + (so2 - 800) * 100 / 800\n",
    "    else:\n",
    "        si = 400 + (so2 - 1600) * 100 / 800\n",
    "    return si\n",
    "\n",
    "# apply the function to calculate si\n",
    "df['si'] = df['so2'].apply(cal_si)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the no2 individual index (ni)\n",
    "def cal_ni(no2):\n",
    "    ni = 0\n",
    "    if (no2 <= 40):\n",
    "        ni = no2 * 50 / 40\n",
    "    elif (no2 <= 80):\n",
    "        ni = 50 + (no2 - 40) * 50 / 40\n",
    "    elif (no2 <= 180):\n",
    "        ni = 100 + (no2 - 80) * 100 / 100\n",
    "    elif (no2 <= 280):\n",
    "        ni = 200 + (no2 - 180) * 100 / 100\n",
    "    elif (no2 <= 400):\n",
    "        ni = 300 + (no2 - 280) * 100 / 120\n",
    "    else:\n",
    "        ni = 400 + (no2 - 400) * 100 / 120\n",
    "    return ni\n",
    "\n",
    "# apply the function to calculate ni\n",
    "df['ni'] = df['no2'].apply(cal_ni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the rspm individual index (rpi)\n",
    "def cal_rpi(rspm):\n",
    "    rpi = 0\n",
    "    if (rspm <= 30):\n",
    "        rpi = rspm * 50 / 30\n",
    "    elif (rspm <= 60):\n",
    "        rpi = 50 + (rspm - 30) * 50 / 30\n",
    "    elif (rspm <= 90):\n",
    "        rpi = 100 + (rspm - 60) * 100 / 30\n",
    "    elif (rspm <= 120):\n",
    "        rpi = 200 + (rspm - 90) * 100 / 30\n",
    "    elif (rspm <= 250):\n",
    "        rpi = 300 + (rspm - 120) * 100 / 130\n",
    "    else:\n",
    "        rpi = 400 + (rspm - 250) * 100 / 130\n",
    "    return rpi\n",
    "\n",
    "# apply the function to calculate rpi\n",
    "df['rpi'] = df['rspm'].apply(cal_rpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the spm individual index (spi)\n",
    "def cal_spi(spm):\n",
    "    spi = 0\n",
    "    if (spm <= 50):\n",
    "        spi = spm\n",
    "    elif (spm <= 100):\n",
    "        spi = spm\n",
    "    elif (spm <= 250):\n",
    "        spi = 100 + (spm - 100) * 100 / 150\n",
    "    elif (spm <= 350):\n",
    "        spi = 200 + (spm - 250)\n",
    "    elif (spm <= 450):\n",
    "        spi = 300 + (spm - 350) * 100 / 100\n",
    "    else:\n",
    "        spi = 400 + (spm - 450) * 100 / 100\n",
    "    return spi\n",
    "\n",
    "# apply the function to calculate spi\n",
    "df['spi'] = df['spm'].apply(cal_spi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the aqi index\n",
    "def cal_aqi(si, ni, rpi, spi):\n",
    "    aqi = 0\n",
    "    if (si > ni and si > rpi and si > spi):\n",
    "        aqi = si\n",
    "    elif (ni > si and ni > rpi and ni > spi):\n",
    "        aqi = ni\n",
    "    elif (rpi > si and rpi > ni and rpi > spi):\n",
    "        aqi = rpi\n",
    "    else:\n",
    "        aqi = spi\n",
    "    return aqi\n",
    "\n",
    "# apply the function to calculate aqi\n",
    "df['AQI'] = df.apply(lambda x: cal_aqi(x['si'], x['ni'], x['rpi'], x['spi']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Andhra Pradesh', 'Arunachal Pradesh', 'Assam', 'Bihar',\n",
       "       'Chandigarh', 'Chhattisgarh', 'Dadra & Nagar Haveli',\n",
       "       'Daman & Diu', 'Delhi', 'Goa', 'Gujarat', 'Haryana',\n",
       "       'Himachal Pradesh', 'Jammu & Kashmir', 'Jharkhand', 'Karnataka',\n",
       "       'Kerala', 'Madhya Pradesh', 'Maharashtra', 'Manipur', 'Meghalaya',\n",
       "       'Mizoram', 'Nagaland', 'Odisha', 'Puducherry', 'Punjab',\n",
       "       'Rajasthan', 'Sikkim', 'Tamil Nadu', 'Telangana', 'Uttar Pradesh',\n",
       "       'Uttarakhand', 'Uttaranchal', 'West Bengal',\n",
       "       'andaman-and-nicobar-islands', 'Lakshadweep', 'Tripura'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find all the unique states in df\n",
    "\n",
    "df['state'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Haldia', 'Howrah', 'Calcutta', 'Durgapur', 'Asansol', 'Kolkata',\n",
       "       'Durgapur (WB)', 'Baruipur', 'Barrackpore', 'Raniganj', 'Sankrail',\n",
       "       'South Suburban', 'DANKUNI', 'HALDIA', 'Kalyani', 'MALDAH',\n",
       "       'SILIGURI', 'ULUBERIA'], dtype=object)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# locate the rows where state is West Bengal\n",
    "df.loc[df['state'] == 'West Bengal'].location.unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "## use ML to prdict AQI of a city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>location</th>\n",
       "      <th>type</th>\n",
       "      <th>so2</th>\n",
       "      <th>no2</th>\n",
       "      <th>rspm</th>\n",
       "      <th>spm</th>\n",
       "      <th>pm2_5</th>\n",
       "      <th>si</th>\n",
       "      <th>ni</th>\n",
       "      <th>rpi</th>\n",
       "      <th>spi</th>\n",
       "      <th>AQI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>415266</th>\n",
       "      <td>West Bengal</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Industrial Area</td>\n",
       "      <td>22.20</td>\n",
       "      <td>104.80</td>\n",
       "      <td>476.00</td>\n",
       "      <td>255.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>27.75</td>\n",
       "      <td>124.80</td>\n",
       "      <td>573.85</td>\n",
       "      <td>205.00</td>\n",
       "      <td>573.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415267</th>\n",
       "      <td>West Bengal</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Industrial Area</td>\n",
       "      <td>22.70</td>\n",
       "      <td>125.50</td>\n",
       "      <td>532.00</td>\n",
       "      <td>268.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>28.38</td>\n",
       "      <td>145.50</td>\n",
       "      <td>616.92</td>\n",
       "      <td>218.00</td>\n",
       "      <td>616.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415268</th>\n",
       "      <td>West Bengal</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Industrial Area</td>\n",
       "      <td>22.50</td>\n",
       "      <td>118.80</td>\n",
       "      <td>446.00</td>\n",
       "      <td>224.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>28.12</td>\n",
       "      <td>138.80</td>\n",
       "      <td>550.77</td>\n",
       "      <td>182.67</td>\n",
       "      <td>550.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415269</th>\n",
       "      <td>West Bengal</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Industrial Area</td>\n",
       "      <td>30.20</td>\n",
       "      <td>120.00</td>\n",
       "      <td>502.00</td>\n",
       "      <td>248.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>37.75</td>\n",
       "      <td>140.00</td>\n",
       "      <td>593.85</td>\n",
       "      <td>198.67</td>\n",
       "      <td>593.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415270</th>\n",
       "      <td>West Bengal</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Industrial Area</td>\n",
       "      <td>19.20</td>\n",
       "      <td>115.20</td>\n",
       "      <td>499.00</td>\n",
       "      <td>242.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>135.20</td>\n",
       "      <td>591.54</td>\n",
       "      <td>194.67</td>\n",
       "      <td>591.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435422</th>\n",
       "      <td>West Bengal</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>RIRUO</td>\n",
       "      <td>4.00</td>\n",
       "      <td>61.00</td>\n",
       "      <td>171.00</td>\n",
       "      <td>187.00</td>\n",
       "      <td>98.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>76.25</td>\n",
       "      <td>339.23</td>\n",
       "      <td>158.00</td>\n",
       "      <td>339.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435423</th>\n",
       "      <td>West Bengal</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>RIRUO</td>\n",
       "      <td>6.00</td>\n",
       "      <td>63.00</td>\n",
       "      <td>217.00</td>\n",
       "      <td>187.00</td>\n",
       "      <td>105.00</td>\n",
       "      <td>7.50</td>\n",
       "      <td>78.75</td>\n",
       "      <td>374.62</td>\n",
       "      <td>158.00</td>\n",
       "      <td>374.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435424</th>\n",
       "      <td>West Bengal</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>RIRUO</td>\n",
       "      <td>7.00</td>\n",
       "      <td>69.00</td>\n",
       "      <td>264.00</td>\n",
       "      <td>187.00</td>\n",
       "      <td>121.00</td>\n",
       "      <td>8.75</td>\n",
       "      <td>86.25</td>\n",
       "      <td>410.77</td>\n",
       "      <td>158.00</td>\n",
       "      <td>410.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435425</th>\n",
       "      <td>West Bengal</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>RIRUO</td>\n",
       "      <td>5.00</td>\n",
       "      <td>58.00</td>\n",
       "      <td>191.00</td>\n",
       "      <td>187.00</td>\n",
       "      <td>89.00</td>\n",
       "      <td>6.25</td>\n",
       "      <td>72.50</td>\n",
       "      <td>354.62</td>\n",
       "      <td>158.00</td>\n",
       "      <td>354.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435426</th>\n",
       "      <td>West Bengal</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>RIRUO</td>\n",
       "      <td>5.00</td>\n",
       "      <td>53.00</td>\n",
       "      <td>202.00</td>\n",
       "      <td>187.00</td>\n",
       "      <td>96.00</td>\n",
       "      <td>6.25</td>\n",
       "      <td>66.25</td>\n",
       "      <td>363.08</td>\n",
       "      <td>158.00</td>\n",
       "      <td>363.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7733 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              state location             type   so2    no2   rspm    spm  \\\n",
       "415266  West Bengal  Kolkata  Industrial Area 22.20 104.80 476.00 255.00   \n",
       "415267  West Bengal  Kolkata  Industrial Area 22.70 125.50 532.00 268.00   \n",
       "415268  West Bengal  Kolkata  Industrial Area 22.50 118.80 446.00 224.00   \n",
       "415269  West Bengal  Kolkata  Industrial Area 30.20 120.00 502.00 248.00   \n",
       "415270  West Bengal  Kolkata  Industrial Area 19.20 115.20 499.00 242.00   \n",
       "...             ...      ...              ...   ...    ...    ...    ...   \n",
       "435422  West Bengal  Kolkata            RIRUO  4.00  61.00 171.00 187.00   \n",
       "435423  West Bengal  Kolkata            RIRUO  6.00  63.00 217.00 187.00   \n",
       "435424  West Bengal  Kolkata            RIRUO  7.00  69.00 264.00 187.00   \n",
       "435425  West Bengal  Kolkata            RIRUO  5.00  58.00 191.00 187.00   \n",
       "435426  West Bengal  Kolkata            RIRUO  5.00  53.00 202.00 187.00   \n",
       "\n",
       "        pm2_5    si     ni    rpi    spi    AQI  \n",
       "415266  32.00 27.75 124.80 573.85 205.00 573.85  \n",
       "415267  32.00 28.38 145.50 616.92 218.00 616.92  \n",
       "415268  32.00 28.12 138.80 550.77 182.67 550.77  \n",
       "415269  32.00 37.75 140.00 593.85 198.67 593.85  \n",
       "415270  32.00 24.00 135.20 591.54 194.67 591.54  \n",
       "...       ...   ...    ...    ...    ...    ...  \n",
       "435422  98.00  5.00  76.25 339.23 158.00 339.23  \n",
       "435423 105.00  7.50  78.75 374.62 158.00 374.62  \n",
       "435424 121.00  8.75  86.25 410.77 158.00 410.77  \n",
       "435425  89.00  6.25  72.50 354.62 158.00 354.62  \n",
       "435426  96.00  6.25  66.25 363.08 158.00 363.08  \n",
       "\n",
       "[7733 rows x 13 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# locate the rows where location is Kolkata\n",
    "df.loc[df['location'] == 'Kolkata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7733, 10)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7733 entries, 415266 to 435426\n",
      "Data columns (total 10 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   so2     7733 non-null   float64\n",
      " 1   no2     7733 non-null   float64\n",
      " 2   rspm    7733 non-null   float64\n",
      " 3   spm     7733 non-null   float64\n",
      " 4   pm2_5   7733 non-null   float64\n",
      " 5   si      7733 non-null   float64\n",
      " 6   ni      7733 non-null   float64\n",
      " 7   rpi     7733 non-null   float64\n",
      " 8   spi     7733 non-null   float64\n",
      " 9   AQI     7733 non-null   float64\n",
      "dtypes: float64(10)\n",
      "memory usage: 664.6 KB\n",
      "(6186, 10)\n",
      "(1547, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 31/42 [00:32<00:09,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuantileRegressor model failed to execute\n",
      "Solver interior-point is not anymore available in SciPy >= 1.11.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:44<00:00,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000126 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2105\n",
      "[LightGBM] [Info] Number of data points in the train set: 6186, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 240.109482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:44<00:00,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Adjusted R-Squared  R-Squared   RMSE  \\\n",
      "Model                                                                 \n",
      "ExtraTreeRegressor                           1.00       1.00   2.48   \n",
      "XGBRegressor                                 1.00       1.00   4.44   \n",
      "GradientBoostingRegressor                    1.00       1.00   5.51   \n",
      "ExtraTreesRegressor                          1.00       1.00   5.67   \n",
      "RandomForestRegressor                        1.00       1.00   7.94   \n",
      "LGBMRegressor                                1.00       1.00   8.20   \n",
      "DecisionTreeRegressor                        1.00       1.00   8.66   \n",
      "HistGradientBoostingRegressor                1.00       1.00   8.66   \n",
      "BaggingRegressor                             0.99       0.99   8.87   \n",
      "MLPRegressor                                 0.99       0.99   9.37   \n",
      "KNeighborsRegressor                          0.99       0.99   9.49   \n",
      "Ridge                                        0.96       0.96  24.33   \n",
      "SGDRegressor                                 0.96       0.96  24.33   \n",
      "BayesianRidge                                0.96       0.96  24.34   \n",
      "RidgeCV                                      0.96       0.96  24.34   \n",
      "Lars                                         0.96       0.96  24.34   \n",
      "LarsCV                                       0.96       0.96  24.34   \n",
      "LassoLarsCV                                  0.96       0.96  24.34   \n",
      "LassoLarsIC                                  0.96       0.96  24.34   \n",
      "TransformedTargetRegressor                   0.96       0.96  24.34   \n",
      "LinearRegression                             0.96       0.96  24.34   \n",
      "LassoCV                                      0.96       0.96  24.35   \n",
      "Lasso                                        0.96       0.96  24.71   \n",
      "LassoLars                                    0.96       0.96  24.71   \n",
      "OrthogonalMatchingPursuitCV                  0.96       0.96  24.90   \n",
      "RANSACRegressor                              0.96       0.96  24.94   \n",
      "ElasticNetCV                                 0.96       0.96  25.75   \n",
      "HuberRegressor                               0.96       0.96  26.01   \n",
      "PoissonRegressor                             0.95       0.95  27.54   \n",
      "LinearSVR                                    0.95       0.95  27.64   \n",
      "PassiveAggressiveRegressor                   0.93       0.93  32.48   \n",
      "OrthogonalMatchingPursuit                    0.93       0.93  33.17   \n",
      "ElasticNet                                   0.93       0.93  33.64   \n",
      "SVR                                          0.92       0.92  34.54   \n",
      "NuSVR                                        0.92       0.92  34.93   \n",
      "AdaBoostRegressor                            0.91       0.91  37.04   \n",
      "TweedieRegressor                             0.88       0.88  42.90   \n",
      "GammaRegressor                               0.81       0.81  54.41   \n",
      "DummyRegressor                              -0.01      -0.00 123.83   \n",
      "GaussianProcessRegressor                    -0.19      -0.18 134.64   \n",
      "KernelRidge                                 -2.87      -2.85 242.73   \n",
      "\n",
      "                               Time Taken  \n",
      "Model                                      \n",
      "ExtraTreeRegressor                   0.04  \n",
      "XGBRegressor                         0.52  \n",
      "GradientBoostingRegressor            1.87  \n",
      "ExtraTreesRegressor                  2.14  \n",
      "RandomForestRegressor                7.38  \n",
      "LGBMRegressor                        0.21  \n",
      "DecisionTreeRegressor                0.20  \n",
      "HistGradientBoostingRegressor        0.79  \n",
      "BaggingRegressor                     0.98  \n",
      "MLPRegressor                         6.78  \n",
      "KNeighborsRegressor                  0.10  \n",
      "Ridge                                0.02  \n",
      "SGDRegressor                         0.09  \n",
      "BayesianRidge                        0.06  \n",
      "RidgeCV                              0.05  \n",
      "Lars                                 0.03  \n",
      "LarsCV                               0.06  \n",
      "LassoLarsCV                          0.05  \n",
      "LassoLarsIC                          0.02  \n",
      "TransformedTargetRegressor           0.02  \n",
      "LinearRegression                     0.02  \n",
      "LassoCV                              0.18  \n",
      "Lasso                                0.02  \n",
      "LassoLars                            0.01  \n",
      "OrthogonalMatchingPursuitCV          0.06  \n",
      "RANSACRegressor                      0.04  \n",
      "ElasticNetCV                         0.18  \n",
      "HuberRegressor                       0.13  \n",
      "PoissonRegressor                     0.04  \n",
      "LinearSVR                            0.03  \n",
      "PassiveAggressiveRegressor           0.02  \n",
      "OrthogonalMatchingPursuit            0.02  \n",
      "ElasticNet                           0.06  \n",
      "SVR                                  3.74  \n",
      "NuSVR                                2.45  \n",
      "AdaBoostRegressor                    1.05  \n",
      "TweedieRegressor                     0.03  \n",
      "GammaRegressor                       0.03  \n",
      "DummyRegressor                       0.04  \n",
      "GaussianProcessRegressor            10.36  \n",
      "KernelRidge                          4.32  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# predict the aqi for the location Kolkata\n",
    "# first we need to create a dataframe with the data of Kolkata and we need to create test and train dataframes. Use lazypredict to find the best model for this dataset and use that model to predict the aqi for Kolkata\n",
    "\n",
    "# create a dataframe with the data of Kolkata\n",
    "df_kolkata = df.loc[df['location'] == 'Kolkata']\n",
    "\n",
    "# drop the object columns\n",
    "df_kolkata.drop(columns=['state', 'location', 'type'], inplace=True)\n",
    "\n",
    "# check the shape of the dataframe\n",
    "print(df_kolkata.shape)\n",
    "\n",
    "# check the basic info of the dataframe\n",
    "df_kolkata.info()\n",
    "\n",
    "# craete test and train dataframes\n",
    "# import train_test_split from sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# create the test and train dataframes\n",
    "train, test = train_test_split(df_kolkata, test_size=0.2, random_state=42)\n",
    "\n",
    "# check the shape of the train and test dataframes\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "# use lazypredict to find the best model for this dataset\n",
    "# import LazyRegressor\n",
    "\n",
    "from lazypredict.Supervised import LazyRegressor\n",
    "\n",
    "# create the model\n",
    "reg = LazyRegressor(verbose=0, ignore_warnings=False, custom_metric=None)\n",
    "\n",
    "# fit the model\n",
    "models, predictions = reg.fit(train.drop(columns=['AQI']), test.drop(columns=['AQI']), train['AQI'], test['AQI'])\n",
    "\n",
    "# print the models\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.12736161095054 %\n"
     ]
    }
   ],
   "source": [
    "# use LinearRegression to predict the aqi for Kolkata\n",
    "# import LinearRegression from sklearn\\\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# create the model\n",
    "model = LinearRegression()\n",
    "\n",
    "# fit the model\n",
    "model.fit(train.drop(columns=['AQI']), train['AQI'])\n",
    "\n",
    "# predict the aqi for test data\n",
    "pred = model.predict(test.drop(columns=['AQI']))\n",
    "\n",
    "# check the accuracy of the model\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "print(r2_score(test['AQI'], pred)*100 , '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the following details:\n",
      "so2: 22.2 \n",
      "\n",
      "no2: 104.8 \n",
      "\n",
      "rspm: 476.0 \n",
      "\n",
      "spm: 255.0 \n",
      "\n",
      "pm2_5: 32.0 \n",
      "\n",
      "si: 27.75 \n",
      "\n",
      "ni: 124.8 \n",
      "\n",
      "rpi: 573.85 \n",
      "\n",
      "spi: 205.0 \n",
      "\n",
      "AQI: 573.85 \n",
      "\n",
      "The predicted AQI is:  596.5795752415531\n"
     ]
    }
   ],
   "source": [
    "# predict AQI for Kolkata using the model based on user input\n",
    "\n",
    "# create a function to take user input\n",
    "def take_input():\n",
    "    print(\"Enter the following details:\")\n",
    "    print(\"so2: \", end=\"\")\n",
    "    so2 = float(input())\n",
    "    print(so2, \"\\n\")\n",
    "    print(\"no2: \", end=\"\")\n",
    "    no2 = float(input())\n",
    "    print(no2, \"\\n\")\n",
    "    print(\"rspm: \", end=\"\")\n",
    "    rspm = float(input())\n",
    "    print(rspm, \"\\n\")\n",
    "    print(\"spm: \", end=\"\")\n",
    "    spm = float(input())\n",
    "    print(spm, \"\\n\")\n",
    "    print(\"pm2_5: \", end=\"\")\n",
    "    pm2_5 = float(input())\n",
    "    print(pm2_5, \"\\n\")\n",
    "    print(\"si: \", end=\"\")\n",
    "    si = float(input())\n",
    "    print(si, \"\\n\")\n",
    "    print(\"ni: \", end=\"\")\n",
    "    ni = float(input())\n",
    "    print(ni, \"\\n\")\n",
    "    print(\"rpi: \", end=\"\")\n",
    "    rpi = float(input())\n",
    "    print(rpi, \"\\n\")\n",
    "    print(\"spi: \", end=\"\")\n",
    "    spi = float(input())\n",
    "    print(spi, \"\\n\")\n",
    "    print(\"AQI: \", end=\"\")\n",
    "    aqi = float(input())\n",
    "    print(aqi, \"\\n\")\n",
    "    return so2, no2, rspm, spm, pm2_5, si, ni, rpi, spi, aqi\n",
    "\n",
    "# take user input\n",
    "so2, no2, rspm, spm, pm2_5, si, ni, rpi, spi, aqi = take_input()\n",
    "\n",
    "# create a dataframe with the user input\n",
    "user_input = pd.DataFrame({'so2': [so2], 'no2': [no2], 'rspm': [rspm], 'spm': [spm], 'pm2_5': [pm2_5], 'si': [si], 'ni': [ni], 'rpi': [rpi], 'spi': [spi], 'AQI': [aqi]})\n",
    "\n",
    "# predict the aqi for the user input\n",
    "pred = model.predict(user_input.drop(columns=['AQI']))\n",
    "\n",
    "# print the predicted aqi\n",
    "print(\"The predicted AQI is: \", pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "Running on public URL: https://1679bd4d2f43bc1dcf.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://1679bd4d2f43bc1dcf.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# implement a gradio interface to take user input and predict the aqi\n",
    "# the boxes to take user input for these variables - so2, no2, rspm, spm, pm2_5, si, ni, rpi, spi, aqi\n",
    "\n",
    "# import gradio\n",
    "import gradio as gr\n",
    "\n",
    "# create a function to predict the aqi\n",
    "def predict_aqi(so2, no2, rspm, spm, pm2_5, si, ni, rpi, spi, aqi):\n",
    "    # create a dataframe with the user input\n",
    "    user_input = pd.DataFrame({'so2': [so2], 'no2': [no2], 'rspm': [rspm], 'spm': [spm], 'pm2_5': [pm2_5], 'si': [si], 'ni': [ni], 'rpi': [rpi], 'spi': [spi], 'AQI': [aqi]})\n",
    "    # predict the aqi for the user input\n",
    "    pred = model.predict(user_input.drop(columns=['AQI']))\n",
    "    # return the predicted aqi\n",
    "    return pred[0]\n",
    "\n",
    "# create the interface\n",
    "iface = gr.Interface(fn=predict_aqi, inputs=['number', 'number', 'number', 'number', 'number', 'number', 'number', 'number', 'number', 'number'], outputs='number')\n",
    "\n",
    "# launch the interface\n",
    "iface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

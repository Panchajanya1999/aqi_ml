{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data from the csv file located inside datasets folder\n",
    "df = pd.read_csv('datasets/data.csv', encoding = \"ISO-8859-1\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stn_code</th>\n",
       "      <th>sampling_date</th>\n",
       "      <th>state</th>\n",
       "      <th>location</th>\n",
       "      <th>agency</th>\n",
       "      <th>type</th>\n",
       "      <th>so2</th>\n",
       "      <th>no2</th>\n",
       "      <th>rspm</th>\n",
       "      <th>spm</th>\n",
       "      <th>location_monitoring_station</th>\n",
       "      <th>pm2_5</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150</td>\n",
       "      <td>February - M021990</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Residential, Rural and other Areas</td>\n",
       "      <td>4.8</td>\n",
       "      <td>17.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1990-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>151</td>\n",
       "      <td>February - M021990</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Industrial Area</td>\n",
       "      <td>3.1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1990-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>152</td>\n",
       "      <td>February - M021990</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Residential, Rural and other Areas</td>\n",
       "      <td>6.2</td>\n",
       "      <td>28.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1990-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150</td>\n",
       "      <td>March - M031990</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Residential, Rural and other Areas</td>\n",
       "      <td>6.3</td>\n",
       "      <td>14.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1990-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151</td>\n",
       "      <td>March - M031990</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Industrial Area</td>\n",
       "      <td>4.7</td>\n",
       "      <td>7.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1990-03-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stn_code       sampling_date           state   location agency  \\\n",
       "0      150  February - M021990  Andhra Pradesh  Hyderabad    NaN   \n",
       "1      151  February - M021990  Andhra Pradesh  Hyderabad    NaN   \n",
       "2      152  February - M021990  Andhra Pradesh  Hyderabad    NaN   \n",
       "3      150     March - M031990  Andhra Pradesh  Hyderabad    NaN   \n",
       "4      151     March - M031990  Andhra Pradesh  Hyderabad    NaN   \n",
       "\n",
       "                                 type  so2   no2  rspm  spm  \\\n",
       "0  Residential, Rural and other Areas  4.8  17.4   NaN  NaN   \n",
       "1                     Industrial Area  3.1   7.0   NaN  NaN   \n",
       "2  Residential, Rural and other Areas  6.2  28.5   NaN  NaN   \n",
       "3  Residential, Rural and other Areas  6.3  14.7   NaN  NaN   \n",
       "4                     Industrial Area  4.7   7.5   NaN  NaN   \n",
       "\n",
       "  location_monitoring_station  pm2_5        date  \n",
       "0                         NaN    NaN  1990-02-01  \n",
       "1                         NaN    NaN  1990-02-01  \n",
       "2                         NaN    NaN  1990-02-01  \n",
       "3                         NaN    NaN  1990-03-01  \n",
       "4                         NaN    NaN  1990-03-01  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 435742 rows and 13 columns in the dataframe\n"
     ]
    }
   ],
   "source": [
    "# check the shape of the dataframe\n",
    "print(f\"There are {df.shape[0]} rows and {df.shape[1]} columns in the dataframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 435742 entries, 0 to 435741\n",
      "Data columns (total 13 columns):\n",
      " #   Column                       Non-Null Count   Dtype  \n",
      "---  ------                       --------------   -----  \n",
      " 0   stn_code                     291665 non-null  object \n",
      " 1   sampling_date                435739 non-null  object \n",
      " 2   state                        435742 non-null  object \n",
      " 3   location                     435739 non-null  object \n",
      " 4   agency                       286261 non-null  object \n",
      " 5   type                         430349 non-null  object \n",
      " 6   so2                          401096 non-null  float64\n",
      " 7   no2                          419509 non-null  float64\n",
      " 8   rspm                         395520 non-null  float64\n",
      " 9   spm                          198355 non-null  float64\n",
      " 10  location_monitoring_station  408251 non-null  object \n",
      " 11  pm2_5                        9314 non-null    float64\n",
      " 12  date                         435735 non-null  object \n",
      "dtypes: float64(5), object(8)\n",
      "memory usage: 43.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# check the basic info of the dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stn_code                        object\n",
       "sampling_date                   object\n",
       "state                           object\n",
       "location                        object\n",
       "agency                          object\n",
       "type                            object\n",
       "so2                            float64\n",
       "no2                            float64\n",
       "rspm                           float64\n",
       "spm                            float64\n",
       "location_monitoring_station     object\n",
       "pm2_5                          float64\n",
       "date                            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the type of data for each column\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pm2_5                          426428\n",
       "spm                            237387\n",
       "agency                         149481\n",
       "stn_code                       144077\n",
       "rspm                            40222\n",
       "so2                             34646\n",
       "location_monitoring_station     27491\n",
       "no2                             16233\n",
       "type                             5393\n",
       "date                                7\n",
       "sampling_date                       3\n",
       "location                            3\n",
       "state                               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for null values in descending order\n",
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agency                         149481\n",
       "stn_code                       144077\n",
       "location_monitoring_station     27491\n",
       "type                             5393\n",
       "date                                7\n",
       "sampling_date                       3\n",
       "location                            3\n",
       "state                               0\n",
       "so2                                 0\n",
       "no2                                 0\n",
       "rspm                                0\n",
       "spm                                 0\n",
       "pm2_5                               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for the float64 columns, fill the null values with the mean of the column\n",
    "# make a list of the float64 columns\n",
    "float64_cols = df.select_dtypes(include=['float64']).columns.tolist()\n",
    "# find the mean and median of each column\n",
    "mean = df[float64_cols].mean()\n",
    "#print(mean)\n",
    "median = df[float64_cols].median()\n",
    "#print(median)\n",
    "\n",
    "# fill the null values with the median of the column\n",
    "df[float64_cols] = df[float64_cols].fillna(median)\n",
    "\n",
    "# check for null values in descending order\n",
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stn_code                        745\n",
       "sampling_date                  5485\n",
       "state                            37\n",
       "location                        304\n",
       "agency                           64\n",
       "type                             10\n",
       "so2                            4197\n",
       "no2                            6864\n",
       "rspm                           6065\n",
       "spm                            6668\n",
       "location_monitoring_station     991\n",
       "pm2_5                           433\n",
       "date                           5067\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for unique values in the dataframe\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "674\n",
      "There are 435068 rows and 13 columns in the dataframe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "stn_code                        745\n",
       "sampling_date                  5485\n",
       "state                            37\n",
       "location                        304\n",
       "agency                           64\n",
       "type                             10\n",
       "so2                            4197\n",
       "no2                            6864\n",
       "rspm                           6065\n",
       "spm                            6668\n",
       "location_monitoring_station     991\n",
       "pm2_5                           433\n",
       "date                           5067\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for duplicate rows in the dataframe\n",
    "print(df.duplicated().sum())\n",
    "\n",
    "# drop the duplicate rows\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# check rows and columns after dropping the duplicates\n",
    "print(f\"There are {df.shape[0]} rows and {df.shape[1]} columns in the dataframe\")\n",
    "\n",
    "# are the unique values in the datraframe got affected?\n",
    "df.nunique()\n",
    "\n",
    "# they are same as before, so we can proceed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the columns which are not required\n",
    "# create a list of columns to be dropped\n",
    "cols_to_drop = ['agency', 'stn_code', 'date', 'sampling_date', 'location_monitoring_station']\n",
    "\n",
    "# drop the columns\n",
    "df.drop(columns=cols_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 435068 entries, 0 to 435741\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count   Dtype  \n",
      "---  ------    --------------   -----  \n",
      " 0   state     435068 non-null  object \n",
      " 1   location  435065 non-null  object \n",
      " 2   type      429711 non-null  object \n",
      " 3   so2       435068 non-null  float64\n",
      " 4   no2       435068 non-null  float64\n",
      " 5   rspm      435068 non-null  float64\n",
      " 6   spm       435068 non-null  float64\n",
      " 7   pm2_5     435068 non-null  float64\n",
      "dtypes: float64(5), object(3)\n",
      "memory usage: 29.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the so2 individual index (si)\n",
    "def cal_si(so2):\n",
    "    si = 0\n",
    "    if (so2 <= 40):\n",
    "        si = so2 * 50 / 40\n",
    "    elif (so2 <= 80):\n",
    "        si = 50 + (so2 - 40) * 50 / 40\n",
    "    elif (so2 <= 380):\n",
    "        si = 100 + (so2 - 80) * 100 / 300\n",
    "    elif (so2 <= 800):\n",
    "        si = 200 + (so2 - 380) * 100 / 420\n",
    "    elif (so2 <= 1600):\n",
    "        si = 300 + (so2 - 800) * 100 / 800\n",
    "    else:\n",
    "        si = 400 + (so2 - 1600) * 100 / 800\n",
    "    return si\n",
    "\n",
    "# apply the function to calculate si\n",
    "df['si'] = df['so2'].apply(cal_si)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the no2 individual index (ni)\n",
    "def cal_ni(no2):\n",
    "    ni = 0\n",
    "    if (no2 <= 40):\n",
    "        ni = no2 * 50 / 40\n",
    "    elif (no2 <= 80):\n",
    "        ni = 50 + (no2 - 40) * 50 / 40\n",
    "    elif (no2 <= 180):\n",
    "        ni = 100 + (no2 - 80) * 100 / 100\n",
    "    elif (no2 <= 280):\n",
    "        ni = 200 + (no2 - 180) * 100 / 100\n",
    "    elif (no2 <= 400):\n",
    "        ni = 300 + (no2 - 280) * 100 / 120\n",
    "    else:\n",
    "        ni = 400 + (no2 - 400) * 100 / 120\n",
    "    return ni\n",
    "\n",
    "# apply the function to calculate ni\n",
    "df['ni'] = df['no2'].apply(cal_ni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the rspm individual index (rpi)\n",
    "def cal_rpi(rspm):\n",
    "    rpi = 0\n",
    "    if (rspm <= 30):\n",
    "        rpi = rspm * 50 / 30\n",
    "    elif (rspm <= 60):\n",
    "        rpi = 50 + (rspm - 30) * 50 / 30\n",
    "    elif (rspm <= 90):\n",
    "        rpi = 100 + (rspm - 60) * 100 / 30\n",
    "    elif (rspm <= 120):\n",
    "        rpi = 200 + (rspm - 90) * 100 / 30\n",
    "    elif (rspm <= 250):\n",
    "        rpi = 300 + (rspm - 120) * 100 / 130\n",
    "    else:\n",
    "        rpi = 400 + (rspm - 250) * 100 / 130\n",
    "    return rpi\n",
    "\n",
    "# apply the function to calculate rpi\n",
    "df['rpi'] = df['rspm'].apply(cal_rpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the spm individual index (spi)\n",
    "def cal_spi(spm):\n",
    "    spi = 0\n",
    "    if (spm <= 50):\n",
    "        spi = spm\n",
    "    elif (spm <= 100):\n",
    "        spi = spm\n",
    "    elif (spm <= 250):\n",
    "        spi = 100 + (spm - 100) * 100 / 150\n",
    "    elif (spm <= 350):\n",
    "        spi = 200 + (spm - 250)\n",
    "    elif (spm <= 450):\n",
    "        spi = 300 + (spm - 350) * 100 / 100\n",
    "    else:\n",
    "        spi = 400 + (spm - 450) * 100 / 100\n",
    "    return spi\n",
    "\n",
    "# apply the function to calculate spi\n",
    "df['spi'] = df['spm'].apply(cal_spi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the aqi index\n",
    "def cal_aqi(si, ni, rpi, spi):\n",
    "    aqi = 0\n",
    "    if (si > ni and si > rpi and si > spi):\n",
    "        aqi = si\n",
    "    elif (ni > si and ni > rpi and ni > spi):\n",
    "        aqi = ni\n",
    "    elif (rpi > si and rpi > ni and rpi > spi):\n",
    "        aqi = rpi\n",
    "    else:\n",
    "        aqi = spi\n",
    "    return aqi\n",
    "\n",
    "# apply the function to calculate aqi\n",
    "df['AQI'] = df.apply(lambda x: cal_aqi(x['si'], x['ni'], x['rpi'], x['spi']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Andhra Pradesh', 'Arunachal Pradesh', 'Assam', 'Bihar',\n",
       "       'Chandigarh', 'Chhattisgarh', 'Dadra & Nagar Haveli',\n",
       "       'Daman & Diu', 'Delhi', 'Goa', 'Gujarat', 'Haryana',\n",
       "       'Himachal Pradesh', 'Jammu & Kashmir', 'Jharkhand', 'Karnataka',\n",
       "       'Kerala', 'Madhya Pradesh', 'Maharashtra', 'Manipur', 'Meghalaya',\n",
       "       'Mizoram', 'Nagaland', 'Odisha', 'Puducherry', 'Punjab',\n",
       "       'Rajasthan', 'Sikkim', 'Tamil Nadu', 'Telangana', 'Uttar Pradesh',\n",
       "       'Uttarakhand', 'Uttaranchal', 'West Bengal',\n",
       "       'andaman-and-nicobar-islands', 'Lakshadweep', 'Tripura'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find all the unique states in df\n",
    "df['state'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Haldia', 'Howrah', 'Calcutta', 'Durgapur', 'Asansol', 'Kolkata',\n",
       "       'Durgapur (WB)', 'Baruipur', 'Barrackpore', 'Raniganj', 'Sankrail',\n",
       "       'South Suburban', 'DANKUNI', 'HALDIA', 'Kalyani', 'MALDAH',\n",
       "       'SILIGURI', 'ULUBERIA'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# locate the rows where state is West Bengal\n",
    "df.loc[df['state'] == 'West Bengal'].location.unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "## use ML to prdict AQI of a city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train dataframe: (412615, 13)\n",
      "Shape of test dataframe: (22453, 13)\n"
     ]
    }
   ],
   "source": [
    "# create test and train dataframes\n",
    "test = df.loc[df['state'] == 'West Bengal']\n",
    "train = df.loc[df['state'] != 'West Bengal']\n",
    "\n",
    "# check the shape of the dataframes\n",
    "print(f\"Shape of train dataframe: {train.shape}\")\n",
    "print(f\"Shape of test dataframe: {test.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lazypredict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# use lazy predict to find the best model for the dataset\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# import the required libraries\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlazypredict\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lazypredict'"
     ]
    }
   ],
   "source": [
    "# use lazy predict to find the best model for the dataset\n",
    "# import the required libraries\n",
    "import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
